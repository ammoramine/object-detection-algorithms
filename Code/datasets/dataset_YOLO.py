"""
    dataset object (data streamer) over image with corresponding boundinx box , and
    labelisation of objects, that outputs an iterable, that gives correspondance,
    between bbox (bounding boxes) , generated by the selective search algorithm,
    and the labelled bounding boxes from the csv
"""

from torch.utils.data import Dataset
import pandas as pd,numpy as np

from PIL import Image,ImageDraw
from pathlib import Path
dir_file = Path(__file__).parent

try:
    from ...Data import data_manager
    from ..utils import bbox_cont, bbox_grid,bbox_mod
except:
    from Code.utils import bbox_mod
    from Data import data_manager
    from Code.utils import bbox_cont, bbox_grid
    from Code.utils import lbdbbox_grid_to_tensor


from torchvision import transforms


class DatasetYOLO(Dataset):
    def __init__(self,mode="train",with_transform = True,S=7,B=2,target_shape=(448,448)):
        """initisation of the dataset
            :mode : can be equal to train, val or test
        """

    ######## init options
        self.data_accessor = data_manager.DataAccessor(mode)
        self.groundTruth = self.read_detections_file()

        self.with_transform = with_transform
        self.S = S
        self.B = B
        self.target_shape = target_shape


        self.labels_to_int = self.get_labels_to_int()
        self.bbox_grid_inst = bbox_grid.BboxGrid( self.S, self.B, img_shape = self.target_shape)
        self.T1 = lbdbbox_grid_to_tensor.LbdBBoxesContToTensor(self.bbox_grid_inst,self.labels_to_int)
        self.to_tensor = transforms.ToTensor()
        self.T2 = transforms.Resize(self.target_shape)

    def get_unique_labels(self):
        codes = self.groundTruth.LabelName.unique()
        labels = data_manager.get_names_from_codes(codes)
        res = [data_manager.background_label] + labels
        return res

    def get_labels_to_int(self):
        labels = self.get_unique_labels()
        labels_to_int = {label:idx for (idx,label) in zip(range(len(labels)),labels)}
        return labels_to_int

    def read_detections_file(self):
        """of filtered labels"""
        return self.data_accessor.read_csv_file()

    def get_pil_image_from_name(self,image_id):
        return self.data_accessor.get_pil_image_from_name(image_id)

    def __len__(self):
        return len(self.groundTruth.groupby("ImageID"))

    def __getitem__(self, idx):
        for i,(imageID, df) in enumerate(self.groundTruth.groupby("ImageID")):
            if i == idx:
                break


        pil_img = self.get_pil_image_from_name(imageID)

        col,row = pil_img.size

        # el = self.groundTruth.iloc[idx]
        bboxes_gd = []
        labels = []
        for row_df,el in df.iterrows():

            bbox = ((el.XMin*col,el.YMin*row),(el.XMax*col,el.YMax*row))
            label_name = data_manager.code_to_name_of_class[el.LabelName]

            bbox = bbox_mod.Bbox.from_extremes(*bbox)
            bboxes_gd.append(bbox)
            labels.append(label_name)


        bboxes_gd_cont = [bbox_cont.BboxCont(bbox_gd,pil_img.size[::-1]) for bbox_gd in bboxes_gd]

        [bbox_cont_gd.set_bbox_for_new_shape(self.target_shape) for bbox_cont_gd in bboxes_gd_cont]



        # from Code.utils import tensor_to_Lblbbox_grid,lbdbbox_grid_to_tensor
        # T1 = lbdbbox_grid_to_tensor.LbdBboxGridToTensor(bbox_grid_inst,self.labels_to_int)
        # T2 = tensor_to_Lblbbox_grid.TensorToLbdBBoxesCont(tensor_shqpe,self.int_to_labels)
        # from the groundtruth bboxes and the the S value, construct a grid of
        # S*S bboxes of same dimensions disjointly covering the image, and associate
        # each cell at most B bounding boxes, compute then for each box, the ground truth,
        # and construct the array

        # construct a class bbox_grid, that takes as input an the value S,B, and the init_shape of
        # image, and outputs the array
        # it computes initially a set of bboxes, takes also as input also the set of gd bboxes
        # for image rescaled to (448,448), and associate the responsabilities,then outputs
        # array for each pair (grid_cell,bbox) of number S^{2}*B

        # add a class that takes as input a bbox, and an init shape of the associatd image
        # introduce transforms of bbox to adapt to the new scale
        # introduce also the computation of the relative positionnal (x,y,w,h) parameteres
        # of a new bbox

        if self.with_transform:
            bbox_gd_cont_to_labels = dict(zip(bboxes_gd_cont, labels))

            inpts = self.T2(self.to_tensor(pil_img))
            outpts = self.T1(bbox_gd_cont_to_labels)

            return inpts,outpts
        else:
            return pil_img,bboxes_gd_cont,labels

    def collate_fn(self,batch):
        inpts,outpts = [],[]
        for inpt,outpt in  batch:
            inpts.append(inpt)
            outpts.append(outpt)
        import torch
        inpts = torch.stack(inpts)
        outpts = torch.stack(outpts)

        return inpts,outpts

    # def draw_bbox_on_image(self,idx):
    #     img, bboxes,labels = self[idx]
    #     for bbox in bboxes:
    #         bbox.draw_on_image(img,False)
    #     img.show()

if __name__ == '__main__':
    from torch.utils.data import DataLoader
    from functools import partial

    dataset = DatasetYOLO(mode="train")

    # collate_fn = partial(dataset.collate_fn,device=device)
    train_loader = DataLoader(dataset, batch_size=10, collate_fn=dataset.collate_fn, drop_last=True,shuffle=True)

